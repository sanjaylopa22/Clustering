# -*- coding: utf-8 -*-
"""Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AzcFBK1zg5rZfSWXljVTFBcJ_LGVYPI8
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

#import the dataset
data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')
data.head(10)

data.shape

data.describe

x = data.iloc[:, [0,1,2,3]].values

kmeans = KMeans(n_clusters=5)
y_kmeans = kmeans.fit_predict(x)
print(y_kmeans)

kmeans.cluster_centers_

Error =[]
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i).fit(x)
    kmeans.fit(x)
    Error.append(kmeans.inertia_)

plt.plot(range(1, 11), Error)
plt.title('Elbow method')
plt.xlabel('No of clusters')
plt.ylabel('Error')
plt.show()

print("The modified output is:")

modikmeans = KMeans(n_clusters=3)
y_modikmeans = modikmeans.fit_predict(x)
print(y_modikmeans)

modikmeans.cluster_centers_

plt.scatter(x[:,0],x[:,1], c=y_modikmeans,cmap='rainbow')

# Hierarchical Clustering
import numpy as np
import matplotlib.pyplot as plt

x = [4, 5, 10, 4, 3, 11, 14 , 6, 10, 12]
y = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]

plt.scatter(x, y)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage

x = [4, 5, 10, 4, 3, 11, 14 , 6, 10, 12]
y = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]

data = list(zip(x, y))

linkage_data = linkage(data, method='ward', metric='euclidean')
dendrogram(linkage_data)

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import AgglomerativeClustering

x = [4, 5, 10, 4, 3, 11, 14 , 6, 10, 12]
y = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]

data = list(zip(x, y))

hierarchical_cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')
labels = hierarchical_cluster.fit_predict(data)

plt.scatter(x, y, c=labels)
plt.show()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.preprocessing import normalize

data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')
data.head()

import scipy.cluster.hierarchy as shc

del data['Iris-setosa']
plt.figure(figsize=(10, 7))  
plt.title("Dendrograms")  
dend = shc.dendrogram(shc.linkage(data, method='ward'))

from sklearn.cluster import AgglomerativeClustering
cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  
cluster.fit_predict(data)

plt.figure(figsize=(10, 7))  
plt.scatter(data['5.1'], data['3.5'], c=cluster.labels_)

plt.figure(figsize=(10, 7))  
plt.scatter(data['1.4'], data['0.2'], c=cluster.labels_)

!pip install https://github.com/scikit-learn-contrib/scikit-learn-extra/archive/master.zip

from sklearn_extra.cluster import KMedoids

#import the dataset
data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')
data.head(10)

x = data.iloc[:, [0,1,2,3]].values
kmedoids = KMedoids(n_clusters=3, random_state=0).fit(x)
ykmed=kmedoids.fit_predict(x)

ykmed

kmedoids.inertia_